### wangkuiyi

- Python API Design Doc imporvement: https://github.com/reyoung/Paddle/pull/6
- Paddle Cloud UI design: https://github.com/PaddlePaddle/cloud/pull/378#pullrequestreview-66318158
- TensorArray design: https://github.com/PaddlePaddle/Paddle/pull/4564#pullrequestreview-66645688
- farm
  - Continuous integration https://github.com/PaddlePaddle/farm/issues/3
  - Unit tests 
    - https://github.com/PaddlePaddle/farm/issues/2 
    - https://github.com/PaddlePaddle/farm/pull/4#pullrequestreview-66841276
  - Branching and releasing model https://github.com/PaddlePaddle/farm/issues/1
- Update LoDTensor design doc https://github.com/PaddlePaddle/Paddle/pull/4579
- Executor https://github.com/PaddlePaddle/Paddle/pull/4537#pullrequestreview-66923299
- Why adding type_defs.h https://github.com/PaddlePaddle/Paddle/issues/4587
- GetCUDADeviceCount https://github.com/PaddlePaddle/Paddle/pull/4595

### reyoung/Yu Yang

* Generate gradient operators when compile-time.
  * Design doc https://github.com/PaddlePaddle/Paddle/pull/4517
  * Step 1. Basic Classes https://github.com/PaddlePaddle/Paddle/pull/4551
  * Step 2. [Done, UnderReview] https://github.com/PaddlePaddle/Paddle/pull/4566

* Change `PADDLE_ONLY_CPU` -> `PADDLE_WITH_GPU`
  * https://github.com/PaddlePaddle/Paddle/pull/4584  
* Simplize `sum_op`, compose its gradient operator
  * https://github.com/PaddlePaddle/Paddle/pull/4562
  * Since there are many kernels started in `sum_grad`, it is not fast either.
* Unify `map` for `OpDescBind` and `OperatorBase`
  * https://github.com/PaddlePaddle/Paddle/pull/4547
* Remove `add_op` since it is duplicated with `sum_op`
  * https://github.com/PaddlePaddle/Paddle/pull/4514
* Use double precision to stablize some gradient checks
  * https://github.com/PaddlePaddle/Paddle/pull/4491
* Simplize Activation in Paddle
  * https://github.com/PaddlePaddle/Paddle/pull/4485
* Stablize gradient test of elementwise-mul
  * https://github.com/PaddlePaddle/Paddle/pull/4478
* Remove `OperatorBase::InferShape`
  * https://github.com/PaddlePaddle/Paddle/pull/4458

* Fix MacOS Compilation error
  * https://github.com/PaddlePaddle/Paddle/pull/4560

### dongzhihong
- Refactorization:
    - Implement the save/load/checkpoint support
        - https://github.com/PaddlePaddle/Paddle/pull/4602
    - fix add operator bug in backward process
        - https://github.com/PaddlePaddle/Paddle/pull/4548
    - remove default delete copy construct method
        - https://github.com/PaddlePaddle/Paddle/pull/4550
    - Discuss  Executor design with @qijun, @helinwang 
        -https://github.com/PaddlePaddle/Paddle/pull/4537

- Reviews
    - Sigmoid Cross Entropy
        - https://github.com/PaddlePaddle/Paddle/pull/4448
    - Leaky Relu activation
        - https://github.com/PaddlePaddle/Paddle/pull/4604
    - Conv Shift operator 
        - https://github.com/PaddlePaddle/Paddle/pull/4591
    - Rmsprop operator
        - https://github.com/PaddlePaddle/Paddle/pull/4565
    - Changing SGD operator
        - https://github.com/PaddlePaddle/Paddle/pull/4586
    - fix bug in backward process
        - https://github.com/PaddlePaddle/Paddle/pull/4582
    - guide AML team to send PRs to improve our documents
        - https://github.com/PaddlePaddle/Paddle/pull/4484
        - https://github.com/PaddlePaddle/Paddle/pull/4549
        - https://github.com/PaddlePaddle/Paddle/pull/4479


### qiaolongfei

#### refactoring

- remove Runtime InferShape for cond op
  - https://github.com/PaddlePaddle/Paddle/pull/4518
- add some check to operator.run
  - https://github.com/PaddlePaddle/Paddle/pull/4544
- use float32 in cond_op
  - https://github.com/PaddlePaddle/Paddle/pull/4546
- refactor rnn infershape
  - https://github.com/PaddlePaddle/Paddle/pull/4553


#### code review
- dynamic recurrent op forward c++ implentation
  - https://github.com/PaddlePaddle/Paddle/pull/4597
- dynamic recurrent op forward c++ implentation
  - https://github.com/PaddlePaddle/Paddle/pull/4597
- Implementing the Adamax optimizer operator
  - https://github.com/PaddlePaddle/Paddle/pull/4538
- Implementing the Adagrad optimizer step operator
  - https://github.com/PaddlePaddle/Paddle/pull/4558
- Changing learning rate from attribute to input(float)
  - https://github.com/PaddlePaddle/Paddle/pull/4568
- Adding Adadelta optimization operator
  - https://github.com/PaddlePaddle/Paddle/pull/4576
- Changing learning rate from type Input(float) to Input(tensor)
  - https://github.com/PaddlePaddle/Paddle/pull/4578
- 

